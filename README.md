<div align="center">
<h1>
 DevOpsPal
</h1>
</div>

<p align="center">
ğŸ¤— <a href="https://huggingface.co" target="_blank">Hugging Face</a> â€¢ 
ğŸ¤– <a href="https://modelscope.cn/" target="_blank">ModelScope</a> â€¢ 
ğŸ’¬ <a href="https://github.com/" target="_blank">WeChat</a>
</p

<div align="center">
<h4 align="center">
    <p>
        <b>ä¸­æ–‡</b> |
        <a href="https://github.com/luban-agi/DevOpsPal/main/README.md">English</a>
    <p>
</h4>
</div>

DevOpsPalæ˜¯å›½å†…é¦–ä¸ªå¼€æºçš„**å¼€å‘è¿ç»´å¤§æ¨¡å‹**ï¼Œä¸»è¦è‡´åŠ›äºåœ¨ DevOps é¢†åŸŸå‘æŒ¥å®é™…ä»·å€¼ã€‚ç›®å‰ï¼ŒDevOpsPal èƒ½å¤Ÿå¸®åŠ©å·¥ç¨‹å¸ˆåœ¨ DevOps ç”Ÿå‘½å‘¨æœŸåšåˆ°æœ‰é—®é¢˜ï¼Œé—® DevOpsPalã€‚

æˆ‘ä»¬å¼€æºäº†ç»è¿‡é«˜è´¨é‡ DevOps è¯­æ–™è®­ç»ƒçš„ Base æ¨¡å‹å’Œç»è¿‡ DevOps QA æ•°æ®å¯¹é½åçš„ Chat æ¨¡å‹ã€‚
åœ¨å¼€å‘è¿ç»´é¢†åŸŸè¯„æµ‹åŸºå‡† [DevOpsEval](https://github.com/luban-agi/DevOps-Eval) ä¸Šï¼ŒDevOpsPal å–å¾—åŒè§„æ¨¡**æœ€ä½³**çš„æ•ˆæœã€‚
æ¬¢è¿é˜…è¯»æˆ‘ä»¬çš„[æŠ€æœ¯æŠ¥å‘Š](https://arxiv.org)è·å–æ›´å¤šä¿¡æ¯ã€‚

<!--
DevOps å°†æ•´ä¸ªé¡¹ç›®ç”Ÿå‘½å‘¨æœŸåˆ’åˆ†ä¸ºäº†ä¸ƒä¸ªé˜¶æ®µï¼Œåˆ†åˆ«ä¸ºï¼šè®¡åˆ’ï¼Œç¼–ç ï¼Œæ„å»ºï¼Œæµ‹è¯•ï¼Œéƒ¨ç½²ï¼Œè¿ç»´ï¼Œè§‚å¯Ÿã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œæ•´ä¸ªå‘¨æœŸå±äºä¸€ä¸ªæ— é™çš„å¾ªç¯ã€‚
<br>
<div  align="center">
 <img src="https://github.com/luban-agi/DevOpsPal/blob/main/image/devops_flow.png" width = "700" height = "350" alt="devops flow" align=center />
</div>

åœ¨è¿™ä¸ªå¾ªç¯ä¸­ï¼Œæ¯ä¸€æ­¥åœ¨å®æ–½çš„æ—¶å€™ï¼Œéƒ½ä¼šäº§ç”Ÿå„ç§çš„é—®é¢˜éœ€è¦å»æœå¯»ç­”æ¡ˆï¼Œæ¯”å¦‚åœ¨æ„å»ºè¿‡ç¨‹ä¸­ï¼Œéœ€è¦äº†è§£æŸä¸ªåŒ…çš„å‡½æ•°ã€‚ä»¥å¾€ä¼šä¸»è¦ä»ç½‘ç»œä¸Šæœç´¢ç›¸å…³çš„ç­”æ¡ˆï¼Œè¿™ä¸€æ­¥ä¼šæ¯”è¾ƒè€—æ—¶ï¼Œè€Œä¸”å¯èƒ½è¿˜æ‰¾ä¸åˆ°æƒ³è¦çš„ç»“æœã€‚

æ‰€ä»¥æˆ‘ä»¬åŸºäºè‡ªå·±æ”¶é›†çš„ DevOps çš„ç›¸å…³æ•°æ®ï¼Œäº§å‡ºäº†é¦–ä¸ªä»¥å¸®åŠ©å·¥ç¨‹å¸ˆåœ¨æ•´ä¸ª DevOps ç”Ÿå‘½å‘¨æœŸä¸­å¯èƒ½é‡åˆ°çš„é—®é¢˜ä¸ºç›®çš„çš„å¤§æ¨¡å‹ï¼Œå–åä¸º DevOpsPalã€‚æˆ‘ä»¬åˆ†åˆ«å¼€æºäº†ç»è¿‡ DevOps è¯­æ–™åŠ è®­è¿‡çš„ Base æ¨¡å‹å’Œç»è¿‡ DevOps QA æ•°æ®å¯¹é½è¿‡åçš„ Chat æ¨¡å‹ã€‚åœ¨ DevOps çš„è¯„æµ‹æ¦œå•ä¸Šï¼Œæˆ‘ä»¬çš„æ¨¡å‹å–å¾—äº†åŒå‚æ•°é‡çº§åˆ« SOTA çš„æ°´å¹³ã€‚ç›¸å…³è®­ç»ƒæ•°æ®é›†å’Œè¯„æµ‹æ•°æ®é›†ä¹Ÿå·²ç»å¼€æºã€‚
-->

å¼€æºæ¨¡å‹å’Œä¸‹è½½é“¾æ¥è§ä¸‹è¡¨ï¼š
|         | åŸºåº§æ¨¡å‹  | å¯¹é½æ¨¡å‹ | å¯¹é½æ¨¡å‹ Int4 é‡åŒ– |
|:-------:|:-------:|:-------:|:-----------------:|
| 7B      | ğŸ¤— [DevOpsPal-7B-Base](https://huggingface.co) | ğŸ¤— [DevOpsPal-7B-Chat](https://huggingface.co) | ğŸ¤— [DevOpsPal-7B-Chat-4bits](https://huggingface.co) |
| 13B     | ğŸ¤— [DevOpsPal-13B-Base](https://huggingface.co) | ğŸ¤— [DevOpsPal-13B-Chat](https://huggingface.co) | ğŸ¤— [DevOpsPal-13B-Chat-4bits](https://huggingface.co) |


# æœ€æ–°æ¶ˆæ¯
- [2023.9.30] å¼€æº DevOpsPal-7B-Base å’Œ DevOpsPal-7B-Chatï¼Œä»¥åŠ Chat ç‰ˆæœ¬çš„ Int4 é‡åŒ–æ¨¡å‹ã€‚

# æ¨¡å‹è¯„æµ‹
Coming soon

# å¿«é€Ÿä½¿ç”¨
æˆ‘ä»¬æä¾›ç®€å•çš„ç¤ºä¾‹æ¥è¯´æ˜å¦‚ä½•åˆ©ç”¨ ğŸ¤— Transformers å¿«é€Ÿä½¿ç”¨ DevopsPal-7B å’Œ DevopsPal-7B-Chatã€‚

## å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```
## Chat æ¨¡å‹æ¨ç†ç¤ºä¾‹

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
from transformers.generation import GenerationConfig

# è¯·æ³¨æ„ï¼šåˆ†è¯å™¨é»˜è®¤è¡Œä¸ºå·²æ›´æ”¹ä¸ºé»˜è®¤å…³é—­ç‰¹æ®Štokenæ”»å‡»é˜²æŠ¤ã€‚
tokenizer = AutoTokenizer.from_pretrained("path_to_DevOpsPal-7B-Chat", trust_remote_code=True)

# é»˜è®¤ä½¿ç”¨è‡ªåŠ¨æ¨¡å¼ï¼Œæ ¹æ®è®¾å¤‡è‡ªåŠ¨é€‰æ‹©ç²¾åº¦
model = AutoModelForCausalLM.from_pretrained("path_to_DevOpsPal-7B-Chat", device_map="auto", trust_remote_code=True).eval()

# å¯æŒ‡å®šä¸åŒçš„ç”Ÿæˆé•¿åº¦ã€top_pç­‰ç›¸å…³è¶…å‚
model.generation_config = GenerationConfig.from_pretrained("path_to_DevOpsPal-7B-Chat", trust_remote_code=True)

# ç¬¬ä¸€è½®å¯¹è¯
response, history = model.chat(tokenizer, "ä½ å¥½", history=None)
print(response)

# ç¬¬äºŒè½®å¯¹è¯
response, history = model.chat(tokenizer, "ã€‚ã€‚ã€‚", history=history)
print(response)

# ç¬¬ä¸‰è½®å¯¹è¯
response, history = model.chat(tokenizer, "ã€‚ã€‚ã€‚", history=history)
print(response)
```
## Base æ¨¡å‹æ¨ç†ç¤ºä¾‹

# æ¨¡å‹è®­ç»ƒ

## æ•°æ®å‡†å¤‡
ä»£ç å†…éƒ¨é€šè¿‡è°ƒç”¨ datasets.load_dataset è¯»å–æ•°æ®ï¼Œæ”¯æŒ load_dataset æ‰€æ”¯æŒçš„æ•°æ®è¯»å–æ–¹å¼ï¼Œæ¯”å¦‚ jsonï¼Œcsvï¼Œè‡ªå®šä¹‰è¯»å–è„šæœ¬ç­‰æ–¹å¼ï¼ˆä½†æ¨èæ•°æ®å‡†å¤‡ä¸º jsonl æ ¼å¼çš„æ–‡ä»¶ï¼‰ã€‚ç„¶åè¿˜éœ€è¦æ›´æ–° `data/dataset_info.json` æ–‡ä»¶ï¼Œå…·ä½“å¯ä»¥å‚è€ƒ `data/README.md`ã€‚

## é¢„è®­ç»ƒ
å¦‚æœæ”¶é›†äº†ä¸€æ‰¹æ–‡æ¡£ä¹‹ç±»çš„è¯­æ–™ï¼ˆæ¯”å¦‚å…¬å¸å†…éƒ¨äº§å“çš„æ–‡æ¡£ï¼‰æƒ³è¦åœ¨ devopspal æ¨¡å‹ä¸ŠåŠ è®­ï¼Œå¯ä»¥æ‰§è¡Œ `scripts/devopspal-pt.sh` æ¥å‘èµ·ä¸€æ¬¡åŠ è®­æ¥è®©æ¨¡å‹å­¦ä¹ åˆ°è¿™æ‰¹æ–‡æ¡£çš„çŸ¥è¯†ï¼Œå…·ä½“ä»£ç å¦‚ä¸‹:

```bash
set -v 

torchrun --nproc_per_node=4 --nnodes=$WORLD_SIZE --master_port=$MASTER_PORT --master_addr=$MASTER_ADDR --node_rank=$RANK src/train_bash.py \
    --deepspeed conf/deepspeed_config.json \    # deepspeed é…ç½®åœ°å€
	--stage pt \    # ä»£è¡¨æ‰§è¡Œ pretrain
    --model_name_or_path path_to_model \    # huggingfaceä¸‹è½½çš„ devopspal æ¨¡å‹åœ°å€
    --do_train \
    --report_to 'tensorboard' \
    --dataset your_corpus \    # æ•°æ®é›†åå­—ï¼Œè¦å’Œåœ¨ dataset_info.json ä¸­å®šä¹‰çš„ä¸€è‡´
    --template default \    # templateï¼Œpretrain å°±æ˜¯ default
    --finetuning_type full \  # å…¨é‡æˆ–è€… lora
    --output_dir path_to_output_checkpoint_path \    # æ¨¡å‹ checkpoint ä¿å­˜çš„è·¯å¾„
    --overwrite_cache \
    --per_device_train_batch_size 8 \    
    --per_device_eval_batch_size 8 \
    --gradient_accumulation_steps 1 \
    --lr_scheduler_type cosine \
    --warmup_ratio 0.05 \
    --evaluation_strategy steps \
    --logging_steps 10 \
    --max_steps 1000 \
    --save_steps 1000 \
    --eval_steps 1000 \
    --learning_rate 5e-6 \
    --plot_loss \
    --max_source_length=2048 \
    --dataloader_num_workers 8 \
    --val_size 0.01 \
    --bf16 \
    --overwrite_output_dir
```

ä½¿ç”¨è€…å¯ä»¥åœ¨è¿™ä¸ªåŸºç¡€ä¸Šè°ƒæ•´æ¥å‘èµ·è‡ªå·±çš„è®­ç»ƒï¼Œæ›´åŠ è¯¦ç»†çš„å¯é…ç½®é¡¹å»ºè®®é€šè¿‡ `python src/train_bash.py -h` æ¥è·å–å®Œæ•´çš„å‚æ•°åˆ—è¡¨ã€‚

## æŒ‡ä»¤å¾®è°ƒ
å¦‚æœæ”¶é›†äº†ä¸€æ‰¹ QA æ•°æ®æƒ³è¦é’ˆå¯¹ devopspal å†è¿›è¡Œå¯¹é½çš„è¯ï¼Œå¯ä»¥æ‰§è¡Œ `scripts/devopspal-sft.sh` æ¥å‘èµ·ä¸€æ¬¡åŠ è®­æ¥è®©æ¨¡å‹åœ¨æ”¶é›†åˆ°çš„æ¨¡å‹ä¸Šè¿›è¡Œå¯¹é½ï¼Œå…·ä½“ä»£ç å¦‚ä¸‹:
```bash
set -v 

torchrun --nproc_per_node=2 --nnodes=$WORLD_SIZE --master_port=$MASTER_PORT --master_addr=$MASTER_ADDR --node_rank=$RANK src/train_bash.py \
    --deepspeed conf/deepspeed_config.json \    # deepspeed é…ç½®åœ°å€
	--stage pt \    # ä»£è¡¨æ‰§è¡Œ pretrain
    --model_name_or_path path_to_model \    # huggingfaceä¸‹è½½çš„æ¨¡å‹åœ°å€
    --do_train \
    --report_to 'tensorboard' \
    --dataset your_corpus \    # æ•°æ®é›†åå­—ï¼Œè¦å’Œåœ¨ dataset_info.json ä¸­å®šä¹‰çš„ä¸€è‡´
    --template chatml \    # template qwen æ¨¡å‹å›ºå®šå†™ chatml
    --finetuning_type full \    # å…¨é‡æˆ–è€… lora
    --output_dir /mnt/llm/devopspal/model/trained \     # æ¨¡å‹ checkpoint ä¿å­˜çš„è·¯å¾„
    --overwrite_cache \
    --per_device_train_batch_size 8 \
    --per_device_eval_batch_size 8 \
    --gradient_accumulation_steps 1 \
    --lr_scheduler_type cosine \
    --warmup_ratio 0.05 \
    --evaluation_strategy steps \
    --logging_steps 10 \
    --max_steps 1000 \
    --save_steps 100 \
    --eval_steps 100 \
    --learning_rate 5e-5 \
    --plot_loss \
    --max_source_length=2048 \
    --dataloader_num_workers 8 \
    --val_size 0.01 \
    --bf16 \
    --overwrite_output_dir
```

ä½¿ç”¨è€…å¯ä»¥åœ¨è¿™ä¸ªåŸºç¡€ä¸Šè°ƒæ•´æ¥å‘èµ·è‡ªå·±çš„ SFT è®­ç»ƒï¼Œæ›´åŠ è¯¦ç»†çš„å¯é…ç½®é¡¹å»ºè®®é€šè¿‡ `python src/train_bash.py -h` æ¥è·å–å®Œæ•´çš„å‚æ•°åˆ—è¡¨ã€‚

## é‡åŒ–
æˆ‘ä»¬æä¾›äº† DevOpsPal-Chat ç³»åˆ—çš„é‡åŒ–æ¨¡å‹ï¼Œå½“ç„¶ä¹Ÿå¯ä»¥é€šè¿‡ä»¥ä¸‹ä»£ç æ¥é‡åŒ–è‡ªå·±åŠ è®­è¿‡çš„æ¨¡å‹

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
from optimum.gptq import GPTQQuantizer, load_quantized_model
import torch

# åŠ è½½æ¨¡å‹
model_name = "path_of_your_model"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16)

# åŠ è½½æ•°æ®
# todo

# å¼€å§‹é‡åŒ–
quantizer = GPTQQuantizer(bits=4, dataset="c4", block_name_to_quantize = "model.decoder.layers", model_seqlen = 2048)
quantized_model = quantizer.quantize_model(model, tokenizer)

# ä¿å­˜é‡åŒ–åçš„æ¨¡å‹
out_dir = 'save_path_of_your_quantized_model'
quantized_model.save_quantized(out_dir)
```

# æ•°æ®

## é¢„è®­ç»ƒæ•°æ®
DevOps Corpus Coming soon

## æŒ‡ä»¤å¾®è°ƒæ•°æ®
DevOps QA Coming soon

# å…è´£å£°æ˜
ç”±äºè¯­è¨€æ¨¡å‹çš„ç‰¹æ€§ï¼Œæ¨¡å‹ç”Ÿæˆçš„å†…å®¹å¯èƒ½åŒ…å«å¹»è§‰æˆ–è€…æ­§è§†æ€§è¨€è®ºã€‚è¯·è°¨æ…ä½¿ç”¨ DevOpsPal ç³»åˆ—æ¨¡å‹ç”Ÿæˆçš„å†…å®¹ã€‚
å¦‚æœè¦å…¬å¼€ä½¿ç”¨æˆ–å•†ç”¨è¯¥æ¨¡å‹æœåŠ¡ï¼Œè¯·æ³¨æ„æœåŠ¡æ–¹éœ€æ‰¿æ‹…ç”±æ­¤äº§ç”Ÿçš„ä¸è‰¯å½±å“æˆ–æœ‰å®³è¨€è®ºçš„è´£ä»»ï¼Œæœ¬é¡¹ç›®å¼€å‘è€…ä¸æ‰¿æ‹…ä»»ä½•ç”±ä½¿ç”¨æœ¬é¡¹ç›®ï¼ˆåŒ…æ‹¬ä½†ä¸é™äºæ•°æ®ã€æ¨¡å‹ã€ä»£ç ç­‰ï¼‰å¯¼è‡´çš„å±å®³æˆ–æŸå¤±ã€‚

# å¼•ç”¨
å¦‚æœä½¿ç”¨æœ¬é¡¹ç›®çš„ä»£ç ã€æ•°æ®æˆ–æ¨¡å‹ï¼Œè¯·å¼•ç”¨æœ¬é¡¹ç›®è®ºæ–‡ï¼š

é“¾æ¥ï¼š[DevOpsPal](https://arxiv.org)

```
@article{devopspal2023,
  title={},
  author={},
  journal={arXiv preprint arXiv},
  year={2023}
}
```

# è‡´è°¢
æœ¬é¡¹ç›®å‚è€ƒäº†ä»¥ä¸‹å¼€æºé¡¹ç›®ï¼Œåœ¨æ­¤å¯¹ç›¸å…³é¡¹ç›®å’Œç ”ç©¶å¼€å‘äººå‘˜è¡¨ç¤ºæ„Ÿè°¢ã€‚
- [LLaMA-Efficient-Tuning](https://github.com/hiyouga/LLaMA-Efficient-Tuning)

# ç‚¹èµå†å²
[![Star History Chart](https://api.star-history.com/svg?repos=luban-agi/DevOpsPal&type=Date)](https://star-history.com/#luban-agi/DevOpsPal&Date)
